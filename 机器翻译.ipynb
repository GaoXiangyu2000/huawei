{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e59c6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import jieba\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.font_manager import FontProperties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1d6a723",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = \"data/cmn.txt\" \n",
    "## 数据集文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "301abb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_eng(w):\n",
    "    w = w.lower().strip()\n",
    "    # 单词和标点之间加空格\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,])\", r\" \\1 \", w)\n",
    "    # 多个空格合并为一个\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    # 除了(a-z, A-Z, \".\", \"?\", \"!\", \",\")这些字符外，全替换成空格\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", w)\n",
    "    w = w.rstrip().strip()\n",
    "    # 增加开始结束标志，让模型知道何时停止预测\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w\n",
    "def preprocess_chinese(w):\n",
    "    w = w.lower().strip()\n",
    "    w = jieba.cut(w, cut_all=False, HMM=True)\n",
    "    w = \" \".join(list(w)) # 词之间增加空格\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94a7032d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> may i borrow this book ? <end>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.732 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> 我 可以 借 这 本书 吗 ? <end>\n"
     ]
    }
   ],
   "source": [
    "en_sentence = \"May I borrow this book?\"\n",
    "chn_sentence = \"我可以借这本书吗?\"\n",
    "print(preprocess_eng(en_sentence))\n",
    "print(preprocess_chinese(chn_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f91766e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<start> hi . <end>', '<start> 嗨 。 <end>'],\n",
       " ['<start> hi . <end>', '<start> 你好 。 <end>'],\n",
       " ['<start> run . <end>', '<start> 你 用 跑 的 。 <end>'],\n",
       " ['<start> wait ! <end>', '<start> 等等 ！ <end>'],\n",
       " ['<start> hello ! <end>', '<start> 你好 。 <end>'],\n",
       " ['<start> i try . <end>', '<start> 让 我 来 。 <end>'],\n",
       " ['<start> i won ! <end>', '<start> 我 赢 了 。 <end>'],\n",
       " ['<start> oh no ! <end>', '<start> 不会 吧 。 <end>'],\n",
       " ['<start> cheers ! <end>', '<start> 乾杯 ! <end>'],\n",
       " ['<start> he ran . <end>', '<start> 他 跑 了 。 <end>'],\n",
       " ['<start> hop in . <end>', '<start> 跳进来 。 <end>'],\n",
       " ['<start> i lost . <end>', '<start> 我 迷失 了 。 <end>'],\n",
       " ['<start> i quit . <end>', '<start> 我 退出 。 <end>'],\n",
       " ['<start> i m ok . <end>', '<start> 我 沒事 。 <end>'],\n",
       " ['<start> listen . <end>', '<start> 听 着 。 <end>'],\n",
       " ['<start> no way ! <end>', '<start> 不 可能 ！ <end>'],\n",
       " ['<start> no way ! <end>', '<start> 没门 ！ <end>'],\n",
       " ['<start> really ? <end>', '<start> 你 确定 ？ <end>'],\n",
       " ['<start> try it . <end>', '<start> 试试 吧 。 <end>'],\n",
       " ['<start> we try . <end>', '<start> 我们 来 试试 。 <end>']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取数据，每个元素的样式是 [英文, 中文]\n",
    "def create_dataset(path, num_examples=None):\n",
    "    lines = open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "    word_pairs = [[w for w in l.split('\\t')] for l in lines[:num_examples]]\n",
    "    word_pairs = [[preprocess_eng(w[0]), preprocess_chinese(w[1])] for w in word_pairs]\n",
    "    return word_pairs\n",
    "\n",
    "word_pairs = create_dataset(path_to_file)\n",
    "# 展示前 20 个数据\n",
    "word_pairs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cbc8677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> if a person has not had a chance to acquire his target language by the time he s an adult , he s unlikely to be able to reach native speaker level in that language . <end>\n",
      "<start> 如果 一個 人 在 成人 前 沒 有 機會習 得 目標 語言 ， 他 對 該 語言 的 認識 達 到 母語者 程度 的 機會 是 相當 小 的 。 <end>\n",
      "20403 20403\n"
     ]
    }
   ],
   "source": [
    "en, chn = zip(*create_dataset(path_to_file))\n",
    "print(en[-1])\n",
    "print(chn[-1])\n",
    "# 显示数据大小\n",
    "print(len(en), len(chn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14a1b516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "# 取数据中的最大文本长度，用来将所有文本统一成一致的长度，模型才能够正常训练\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "def tokenize(lang):\n",
    "    \"\"\"\n",
    "    1. 分词\n",
    "    2. 转换成 id\n",
    "    3. padding, 将每个句子统一成相同的长度，长度不足的后面补 0\n",
    "    \"\"\"\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    # 生成 词和 id 的映射词典 {word:id}\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "    # 将词转换成对应的 id\n",
    "    text_ids = lang_tokenizer.texts_to_sequences(lang)\n",
    "    # 统一成相同的长度\n",
    "    padded_text_ids = tf.keras.preprocessing.sequence.pad_sequences(text_ids,padding='post')\n",
    "    return padded_text_ids, lang_tokenizer\n",
    "\n",
    "def load_dataset(path,num_examples=None):\n",
    "    # 加载数据，并做预处理\n",
    "    # 将中文设置为源语言，英文设置为目标语言\n",
    "    targ_lang, inp_lang = zip(*create_dataset(path, num_examples))\n",
    "    input_data, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_data, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "    return input_data, target_data, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "007979f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_examples 设置训练数据的大小\n",
    "# num_examples = 10000, 如果num examples = None 则表示不限制大小，所有样本用于训练\n",
    "num_examples = None\n",
    "input_data, target_data, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "# 计算中文数据和英文数据中的最大长度\n",
    "max_length_targ, max_length_inp = max_length(target_data), max_length(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e18de1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19382 19382 1021 1021\n"
     ]
    }
   ],
   "source": [
    "# 分割训练数据和验证数据\n",
    "input_train, input_val, target_train, target_val = train_test_split(input_data, target_data, test_size=0.05)\n",
    "# 显示训练数据和验证数据的大小\n",
    "print(len(input_train), len(target_train),len(input_val), len(target_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "599c3ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入：源语言：中文， 词和 id 的映射关系\n",
      "1 ----> <start>\n",
      "22 ----> 我们\n",
      "66 ----> 今天\n",
      "58 ----> 得\n",
      "20 ----> 去\n",
      "11926 ----> 养老院\n",
      "375 ----> 唱歌\n",
      "3 ----> 。\n",
      "2 ----> <end>\n",
      "\n",
      "输出：目标语言：英文， 词和 id 的映射关系\n",
      "1 ----> <start>\n",
      "28 ----> we\n",
      "21 ----> have\n",
      "6 ----> to\n",
      "549 ----> sing\n",
      "36 ----> at\n",
      "66 ----> an\n",
      "141 ----> old\n",
      "5402 ----> folks\n",
      "102 ----> home\n",
      "132 ----> today\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "## 查看 词和 id 的对应关系\n",
    "def convert(lang, data):\n",
    "    for t in data:\n",
    "        if t != 0:\n",
    "            print(\"%d ----> %s\" % (t, lang.index_word[t]))\n",
    "print(\"输入：源语言：中文， 词和 id 的映射关系\")\n",
    "convert(inp_lang, input_train[0])\n",
    "print()\n",
    "print(\"输出：目标语言：英文， 词和 id 的映射关系\")\n",
    "convert(targ_lang, target_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d903c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b2acf89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 32]), TensorShape([64, 38]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "# 0 是为 padding 保留的一个特殊 id， 所以要 + 1\n",
    "vocab_inp_size = len(inp_lang.word_index) + 1\n",
    "vocab_tar_size = len(targ_lang.word_index) + 1\n",
    "# 先做 shuffle， 再取 batch\n",
    "# see https://stackoverflow.com/questions/50437234/tensorflow-dataset-shuffle-then-batch-or-batch-then-shuffle\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_train, target_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99d4f289",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,vocab_size,embedding_dim,enc_units,batch_sz):\n",
    "        # vacab_size=vocab_inp_size=9394,embedding_dim=256enc_units=1024batch_sz=64\n",
    "        super(Encoder,self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size,embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       #recurrent_activation='sigmoid',\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "    def call(self,x,hidden):\n",
    "        # x 是训练数据，shape==(batch_size，max_length)  ->(64,46)\n",
    "        # embedding 后得到每个词的词向量,xshape==(batch_size,max_length,embedding_dim)->(64,46,256)\n",
    "        x = self.embedding(x)\n",
    "    \n",
    "        # 在GRU中，每一个时间步，输出层和隐藏层是相等的\n",
    "        # output 是所有时间步的输出层输出 shape==(batch_size,max_length,units)->(64,46,1024)\n",
    "        # state 是最后一个时间步的隐藏层输出,shape==(batch_size,units)->(64,1024)\n",
    "        output,state=self.gru(x,initial_state=hidden)\n",
    "        \n",
    "        return output,state\n",
    "        \n",
    "    def initialize_hidden_state(self):\n",
    "        # 初始化gru的隐层参数,shape==(batch_size,units)->(64,1024)\n",
    "        return tf.zeros((self.batch_sz,self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bb546d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder 输出的维度: (batch size, sequence length, units) (64, 32, 1024)\n",
      "Encoder 隐层的维度: (batch size, units) (64, 1024)\n",
      "tf.Tensor([ True  True  True ...  True  True  True], shape=(1024,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "# encoder 示例输出\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print('Encoder 输出的维度: (batch size, sequence length, units) {}'.format(\n",
    "sample_output.shape))\n",
    "print('Encoder 隐层的维度: (batch size, units) {}'.format(sample_hidden.shape))\n",
    "# GRU,在每一个时间步，隐层和输出层是相等的\n",
    "print(sample_output[-1, -1, :] == sample_hidden[-1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4dfbb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self,units):\n",
    "        super(BahdanauAttention,self).__init__()\n",
    "        self.W1=tf.keras.layers.Dense(units)\n",
    "        self.W2=tf.keras.layers.Dense(units)\n",
    "        self.V=tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self,query,values):\n",
    "        # queryshape == (batch_size,hiddensize)\n",
    "        # 扩展时间维度shape == (batch_size,1,hiddensize)\n",
    "        # 为了计算后面的score\n",
    "        hidden_with_time_axis=tf.expand_dims(query,1)\n",
    "        \n",
    "        # scoreshape == (batch_size,max_length,1)\n",
    "        # score 维度为1是因为应用了self.V,V的维度是1\n",
    "        # 应用 self.V 前后的维度是(batch_size,max_length,units)-->(batch_size,max_length,1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(values)+self.W2(hidden_with_time_axis)))\n",
    "        \n",
    "        # 使用 softmax 得到 attention 的权重，attention_weightsshape == (batch_size,max_length,1)\n",
    "        attention_weights = tf.nn.softmax(score,axis=1)\n",
    "        \n",
    "        # context_vectorshape == (batch_size,max_length,hidden_size)\n",
    "        context_vector = attention_weights*values\n",
    "        # 相加后的 attention 上下文向量的维度：shape context_vector == (batch_size,hidden_size)\n",
    "        context_vector = tf.reduce_sum(context_vector,axis=1)\n",
    "        \n",
    "        return context_vector,attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc107f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention输出的维度:(batchsize,units)(64, 1024)\n",
      "Attention权值参数的维度:(batch_size,sequence_length,1)(64, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result,attention_weights = attention_layer(sample_hidden,sample_output)\n",
    "\n",
    "print(\"Attention输出的维度:(batchsize,units){}\".format(attention_result.shape))\n",
    "print(\"Attention权值参数的维度:(batch_size,sequence_length,1){}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc3df4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,vocab_size,embedding_dim,dec_units,batch_sz):\n",
    "        # vocab_size=vocab_tar_size=6082,embedding_dim=256,dec_units=1024,batch_sz=64\n",
    "        super(Decoder,self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size,embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        # 输出的维度是目标语言词汇表的大小，返回的是softmax概率，词汇表中每一个词的概率\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        # attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "    def call(self,x,hidden,enc_output):\n",
    "        # This function outputs a result at each timestamp\n",
    "        \n",
    "        # 计算 decoder 的第一个隐状态和 encoder 所有输入之间的 attention 权重，得到上下文向量,context_vector\n",
    "        context_vector,attention_weights = self.attention(hidden,enc_output)\n",
    "        \n",
    "        # embedding后的维度 == (batch_size,1,embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # 把上下文向量 context_vector 和输入 embedding 拼接在一起\n",
    "        # context_vectorshape == (batch_size,units)->(64,1024)\n",
    "        # 拼接后的数据维度 == (batch_size,1,embedding_dim+hidden_size)->(64,1,1024+256)\n",
    "        x = tf.concat([tf.expand_dims(context_vector,1),x],axis=-1)\n",
    "        \n",
    "        # 把拼接后的向量输入gru\n",
    "        # 得到当前时间步的输出和隐状态\n",
    "        # output shape == (batch_size,1,units)->(64,1,1024),state shape == (batch_size,units)->(64,1024)\n",
    "        output,state=self.gru(x)\n",
    "        \n",
    "        #output shape == (batch_size,hidden_size=1024)\n",
    "        output = tf.reshape(output,(-1,output.shape[2]))\n",
    "        \n",
    "        #output shape == (batch_size,vocab)->(64,6082)\n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x,state,attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56772c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder输出的维度:(batch_size,vocabsize)(64, 6095)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size,embedding_dim,units,BATCH_SIZE)\n",
    "sample_decoder_output,_,_=decoder(tf.random.uniform((64,1)),sample_hidden,sample_output)\n",
    "print('Decoder输出的维度:(batch_size,vocabsize){}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b361df68",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18c39f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real,pred):\n",
    "    \"\"\"Calculate the loss value\n",
    "    \n",
    "    Args:\n",
    "         real:the true label shape == (batch_size,)->(64,)\n",
    "         pred:the probability of each word from the vocabulary,is the output from the decoder\n",
    "         shape == (batch_size,vocab_size)->(64,6082)\n",
    "    Returns:\n",
    "         theaveragelossofthedatainabatchsize\n",
    "    \"\"\"\n",
    "    \n",
    "    mask = tf.math.logical_not(tf.math.equal(real,0))\n",
    "    loss_=loss_object(real,pred)\n",
    "    \n",
    "    mask = tf.cast(mask,dtype=loss_.dtype)\n",
    "    loss_*=mask\n",
    "    \n",
    "    return tf.reduce_mean(loss_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e4e5da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'checkpoints/chinese-eng'\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir,\"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,encoder = encoder,decoder = decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9ae3d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inp,targ,enc_hidden):\n",
    "    loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output,enc_hidden = encoder(inp,enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        # feed the <start> as the first input of the decoder\n",
    "        # dec input shape == (batch_size,1)->(64,1)\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']]*BATCH_SIZE,1)\n",
    "        # Teacher forcing-feeding the target as the next input\n",
    "        # because of the data preprocessing(add a start token to the sentence)\n",
    "        # the first word is <start>,so t starts from 1(not0)\n",
    "        for t in range(1,targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions,dec_hidden,_= decoder(dec_input,dec_hidden,enc_output)\n",
    "            # targ[:,t] is the true label(index of the word) of every sentence(inabatch) at the current timestamp\n",
    "            # like [85182525···10477913],shape == (batch_size,)->(64,)\n",
    "            # predictions shape == (batch_size,vocab_size)->(64,6082)\n",
    "            loss += loss_function(targ[:,t],predictions)\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:,t],1)\n",
    "        \n",
    "    batch_loss=(loss/int(targ.shape[1]))\n",
    "    \n",
    "    # collect all trainable variables\n",
    "    variables = encoder.trainable_variables+decoder.trainable_variables\n",
    "    \n",
    "    # calculate the gradients for the whole variables\n",
    "    gradients = tape.gradient(loss,variables)\n",
    "    \n",
    "    # apply the gradients on the variables\n",
    "    optimizer.apply_gradients(zip(gradients,variables))\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e640cf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 2.0499\n",
      "Epoch 1 Batch 100 Loss 1.0524\n",
      "Epoch 1 Batch 200 Loss 0.9937\n",
      "Epoch 1 Batch 300 Loss 0.9547\n",
      "Epoch 1 Loss 1.0522\n",
      "Time taken for 1 epoch 168.66971230506897 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.8400\n",
      "Epoch 2 Batch 100 Loss 0.7481\n",
      "Epoch 2 Batch 200 Loss 0.8201\n",
      "Epoch 2 Batch 300 Loss 0.7349\n",
      "Epoch 2 Loss 0.8118\n",
      "Time taken for 1 epoch 168.97227001190186 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.7042\n",
      "Epoch 3 Batch 100 Loss 0.7168\n",
      "Epoch 3 Batch 200 Loss 0.6355\n",
      "Epoch 3 Batch 300 Loss 0.6676\n",
      "Epoch 3 Loss 0.6721\n",
      "Time taken for 1 epoch 166.24021863937378 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.5999\n",
      "Epoch 4 Batch 100 Loss 0.4329\n",
      "Epoch 4 Batch 200 Loss 0.5563\n",
      "Epoch 4 Batch 300 Loss 0.5891\n",
      "Epoch 4 Loss 0.5438\n",
      "Time taken for 1 epoch 163.0361590385437 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.4493\n",
      "Epoch 5 Batch 100 Loss 0.3667\n",
      "Epoch 5 Batch 200 Loss 0.4546\n",
      "Epoch 5 Batch 300 Loss 0.4625\n",
      "Epoch 5 Loss 0.4251\n",
      "Time taken for 1 epoch 168.37319350242615 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.3115\n",
      "Epoch 6 Batch 100 Loss 0.2914\n",
      "Epoch 6 Batch 200 Loss 0.3553\n",
      "Epoch 6 Batch 300 Loss 0.3335\n",
      "Epoch 6 Loss 0.3228\n",
      "Time taken for 1 epoch 171.50059413909912 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.1942\n",
      "Epoch 7 Batch 100 Loss 0.2348\n",
      "Epoch 7 Batch 200 Loss 0.2514\n",
      "Epoch 7 Batch 300 Loss 0.2549\n",
      "Epoch 7 Loss 0.2396\n",
      "Time taken for 1 epoch 168.68880701065063 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.1450\n",
      "Epoch 8 Batch 100 Loss 0.1535\n",
      "Epoch 8 Batch 200 Loss 0.1856\n",
      "Epoch 8 Batch 300 Loss 0.1821\n",
      "Epoch 8 Loss 0.1778\n",
      "Time taken for 1 epoch 166.39608502388 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.1271\n",
      "Epoch 9 Batch 100 Loss 0.1223\n",
      "Epoch 9 Batch 200 Loss 0.1902\n",
      "Epoch 9 Batch 300 Loss 0.1757\n",
      "Epoch 9 Loss 0.1349\n",
      "Time taken for 1 epoch 160.59418773651123 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0831\n",
      "Epoch 10 Batch 100 Loss 0.1167\n",
      "Epoch 10 Batch 200 Loss 0.0975\n",
      "Epoch 10 Batch 300 Loss 0.0992\n",
      "Epoch 10 Loss 0.0987\n",
      "Time taken for 1 epoch 162.49205422401428 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.0676\n",
      "Epoch 11 Batch 100 Loss 0.1033\n",
      "Epoch 11 Batch 200 Loss 0.0890\n",
      "Epoch 11 Batch 300 Loss 0.1092\n",
      "Epoch 11 Loss 0.0811\n",
      "Time taken for 1 epoch 158.65518164634705 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.0548\n",
      "Epoch 12 Batch 100 Loss 0.0495\n",
      "Epoch 12 Batch 200 Loss 0.0492\n",
      "Epoch 12 Batch 300 Loss 0.0626\n",
      "Epoch 12 Loss 0.0573\n",
      "Time taken for 1 epoch 163.68128848075867 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.0399\n",
      "Epoch 13 Batch 100 Loss 0.0386\n",
      "Epoch 13 Batch 200 Loss 0.0372\n",
      "Epoch 13 Batch 300 Loss 0.0474\n",
      "Epoch 13 Loss 0.0426\n",
      "Time taken for 1 epoch 167.48180389404297 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.0336\n",
      "Epoch 14 Batch 100 Loss 0.0409\n",
      "Epoch 14 Batch 200 Loss 0.0275\n",
      "Epoch 14 Batch 300 Loss 0.0295\n",
      "Epoch 14 Loss 0.0326\n",
      "Time taken for 1 epoch 169.03312253952026 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.0288\n",
      "Epoch 15 Batch 100 Loss 0.0194\n",
      "Epoch 15 Batch 200 Loss 0.0144\n",
      "Epoch 15 Batch 300 Loss 0.0232\n",
      "Epoch 15 Loss 0.0253\n",
      "Time taken for 1 epoch 169.36295104026794 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.0133\n",
      "Epoch 16 Batch 100 Loss 0.0188\n",
      "Epoch 16 Batch 200 Loss 0.0228\n",
      "Epoch 16 Batch 300 Loss 0.0296\n",
      "Epoch 16 Loss 0.0213\n",
      "Time taken for 1 epoch 169.1491117477417 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.0166\n",
      "Epoch 17 Batch 100 Loss 0.0178\n",
      "Epoch 17 Batch 200 Loss 0.0127\n",
      "Epoch 17 Batch 300 Loss 0.0250\n",
      "Epoch 17 Loss 0.0192\n",
      "Time taken for 1 epoch 167.15051007270813 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.0507\n",
      "Epoch 18 Batch 100 Loss 0.0153\n",
      "Epoch 18 Batch 200 Loss 0.0213\n",
      "Epoch 18 Batch 300 Loss 0.0252\n",
      "Epoch 18 Loss 0.0188\n",
      "Time taken for 1 epoch 158.35304474830627 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.0272\n",
      "Epoch 19 Batch 100 Loss 0.0133\n",
      "Epoch 19 Batch 200 Loss 0.0268\n",
      "Epoch 19 Batch 300 Loss 0.0236\n",
      "Epoch 19 Loss 0.0192\n",
      "Time taken for 1 epoch 159.4501988887787 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.0140\n",
      "Epoch 20 Batch 100 Loss 0.0205\n",
      "Epoch 20 Batch 200 Loss 0.0168\n",
      "Epoch 20 Batch 300 Loss 0.0177\n",
      "Epoch 20 Loss 0.0198\n",
      "Time taken for 1 epoch 160.84368443489075 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.0163\n",
      "Epoch 21 Batch 100 Loss 0.0303\n",
      "Epoch 21 Batch 200 Loss 0.0251\n",
      "Epoch 21 Batch 300 Loss 0.0273\n",
      "Epoch 21 Loss 0.0213\n",
      "Time taken for 1 epoch 168.19161891937256 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.0104\n",
      "Epoch 22 Batch 100 Loss 0.0197\n",
      "Epoch 22 Batch 200 Loss 0.0281\n",
      "Epoch 22 Batch 300 Loss 0.0270\n",
      "Epoch 22 Loss 0.0243\n",
      "Time taken for 1 epoch 170.82762002944946 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.0097\n",
      "Epoch 23 Batch 100 Loss 0.0200\n",
      "Epoch 23 Batch 200 Loss 0.0185\n",
      "Epoch 23 Batch 300 Loss 0.0273\n",
      "Epoch 23 Loss 0.0216\n",
      "Time taken for 1 epoch 171.65735745429993 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.0169\n",
      "Epoch 24 Batch 100 Loss 0.0158\n",
      "Epoch 24 Batch 200 Loss 0.0173\n",
      "Epoch 24 Batch 300 Loss 0.0179\n",
      "Epoch 24 Loss 0.0184\n",
      "Time taken for 1 epoch 169.03080415725708 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.0179\n",
      "Epoch 25 Batch 100 Loss 0.0333\n",
      "Epoch 25 Batch 200 Loss 0.0318\n",
      "Epoch 25 Batch 300 Loss 0.0435\n",
      "Epoch 25 Loss 0.0249\n",
      "Time taken for 1 epoch 164.78806257247925 sec\n",
      "\n",
      "Epoch 26 Batch 0 Loss 0.0318\n",
      "Epoch 26 Batch 100 Loss 0.0323\n",
      "Epoch 26 Batch 200 Loss 0.0182\n",
      "Epoch 26 Batch 300 Loss 0.0260\n",
      "Epoch 26 Loss 0.0213\n",
      "Time taken for 1 epoch 166.9929494857788 sec\n",
      "\n",
      "Epoch 27 Batch 0 Loss 0.0199\n",
      "Epoch 27 Batch 100 Loss 0.0062\n",
      "Epoch 27 Batch 200 Loss 0.0261\n",
      "Epoch 27 Batch 300 Loss 0.0210\n",
      "Epoch 27 Loss 0.0166\n",
      "Time taken for 1 epoch 166.66358137130737 sec\n",
      "\n",
      "Epoch 28 Batch 0 Loss 0.0117\n",
      "Epoch 28 Batch 100 Loss 0.0108\n",
      "Epoch 28 Batch 200 Loss 0.0209\n",
      "Epoch 28 Batch 300 Loss 0.0153\n",
      "Epoch 28 Loss 0.0133\n",
      "Time taken for 1 epoch 167.31272387504578 sec\n",
      "\n",
      "Epoch 29 Batch 0 Loss 0.0094\n",
      "Epoch 29 Batch 100 Loss 0.0067\n",
      "Epoch 29 Batch 200 Loss 0.0139\n",
      "Epoch 29 Batch 300 Loss 0.0221\n",
      "Epoch 29 Loss 0.0118\n",
      "Time taken for 1 epoch 163.9309184551239 sec\n",
      "\n",
      "Epoch 30 Batch 0 Loss 0.0058\n",
      "Epoch 30 Batch 100 Loss 0.0144\n",
      "Epoch 30 Batch 200 Loss 0.0119\n",
      "Epoch 30 Batch 300 Loss 0.0158\n",
      "Epoch 30 Loss 0.0118\n",
      "Time taken for 1 epoch 163.12243914604187 sec\n",
      "\n",
      "Epoch 31 Batch 0 Loss 0.0136\n",
      "Epoch 31 Batch 100 Loss 0.0137\n",
      "Epoch 31 Batch 200 Loss 0.0141\n",
      "Epoch 31 Batch 300 Loss 0.0124\n",
      "Epoch 31 Loss 0.0115\n",
      "Time taken for 1 epoch 161.4167082309723 sec\n",
      "\n",
      "Epoch 32 Batch 0 Loss 0.0081\n",
      "Epoch 32 Batch 100 Loss 0.0058\n",
      "Epoch 32 Batch 200 Loss 0.0138\n",
      "Epoch 32 Batch 300 Loss 0.0165\n",
      "Epoch 32 Loss 0.0109\n",
      "Time taken for 1 epoch 163.0166928768158 sec\n",
      "\n",
      "Epoch 33 Batch 0 Loss 0.0140\n",
      "Epoch 33 Batch 100 Loss 0.0045\n",
      "Epoch 33 Batch 200 Loss 0.0176\n",
      "Epoch 33 Batch 300 Loss 0.0100\n",
      "Epoch 33 Loss 0.0110\n",
      "Time taken for 1 epoch 161.12784671783447 sec\n",
      "\n",
      "Epoch 34 Batch 0 Loss 0.0089\n",
      "Epoch 34 Batch 100 Loss 0.0101\n",
      "Epoch 34 Batch 200 Loss 0.0154\n",
      "Epoch 34 Batch 300 Loss 0.0228\n",
      "Epoch 34 Loss 0.0142\n",
      "Time taken for 1 epoch 163.5709822177887 sec\n",
      "\n",
      "Epoch 35 Batch 0 Loss 0.0158\n",
      "Epoch 35 Batch 100 Loss 0.0104\n",
      "Epoch 35 Batch 200 Loss 0.0239\n",
      "Epoch 35 Batch 300 Loss 0.0208\n",
      "Epoch 35 Loss 0.0168\n",
      "Time taken for 1 epoch 159.16986727714539 sec\n",
      "\n",
      "Epoch 36 Batch 0 Loss 0.0211\n",
      "Epoch 36 Batch 100 Loss 0.0068\n",
      "Epoch 36 Batch 200 Loss 0.0163\n",
      "Epoch 36 Batch 300 Loss 0.0285\n",
      "Epoch 36 Loss 0.0162\n",
      "Time taken for 1 epoch 163.98217153549194 sec\n",
      "\n",
      "Epoch 37 Batch 0 Loss 0.0369\n",
      "Epoch 37 Batch 100 Loss 0.0237\n",
      "Epoch 37 Batch 200 Loss 0.0295\n",
      "Epoch 37 Batch 300 Loss 0.0369\n",
      "Epoch 37 Loss 0.0237\n",
      "Time taken for 1 epoch 161.18763160705566 sec\n",
      "\n",
      "Epoch 38 Batch 0 Loss 0.0181\n",
      "Epoch 38 Batch 100 Loss 0.0126\n",
      "Epoch 38 Batch 200 Loss 0.0062\n",
      "Epoch 38 Batch 300 Loss 0.0147\n",
      "Epoch 38 Loss 0.0156\n",
      "Time taken for 1 epoch 156.7990894317627 sec\n",
      "\n",
      "Epoch 39 Batch 0 Loss 0.0087\n",
      "Epoch 39 Batch 100 Loss 0.0051\n",
      "Epoch 39 Batch 200 Loss 0.0134\n",
      "Epoch 39 Batch 300 Loss 0.0098\n",
      "Epoch 39 Loss 0.0128\n",
      "Time taken for 1 epoch 158.02785086631775 sec\n",
      "\n",
      "Epoch 40 Batch 0 Loss 0.0110\n",
      "Epoch 40 Batch 100 Loss 0.0126\n",
      "Epoch 40 Batch 200 Loss 0.0147\n",
      "Epoch 40 Batch 300 Loss 0.0193\n",
      "Epoch 40 Loss 0.0105\n",
      "Time taken for 1 epoch 161.8535668849945 sec\n",
      "\n",
      "Epoch 41 Batch 0 Loss 0.0070\n",
      "Epoch 41 Batch 100 Loss 0.0095\n",
      "Epoch 41 Batch 200 Loss 0.0170\n",
      "Epoch 41 Batch 300 Loss 0.0089\n",
      "Epoch 41 Loss 0.0089\n",
      "Time taken for 1 epoch 164.58192348480225 sec\n",
      "\n",
      "Epoch 42 Batch 0 Loss 0.0024\n",
      "Epoch 42 Batch 100 Loss 0.0052\n",
      "Epoch 42 Batch 200 Loss 0.0025\n",
      "Epoch 42 Batch 300 Loss 0.0084\n",
      "Epoch 42 Loss 0.0082\n",
      "Time taken for 1 epoch 161.00118374824524 sec\n",
      "\n",
      "Epoch 43 Batch 0 Loss 0.0096\n",
      "Epoch 43 Batch 100 Loss 0.0150\n",
      "Epoch 43 Batch 200 Loss 0.0113\n",
      "Epoch 43 Batch 300 Loss 0.0144\n",
      "Epoch 43 Loss 0.0079\n",
      "Time taken for 1 epoch 161.42690134048462 sec\n",
      "\n",
      "Epoch 44 Batch 0 Loss 0.0066\n",
      "Epoch 44 Batch 100 Loss 0.0068\n",
      "Epoch 44 Batch 200 Loss 0.0107\n",
      "Epoch 44 Batch 300 Loss 0.0141\n",
      "Epoch 44 Loss 0.0076\n",
      "Time taken for 1 epoch 163.53838729858398 sec\n",
      "\n",
      "Epoch 45 Batch 0 Loss 0.0041\n",
      "Epoch 45 Batch 100 Loss 0.0128\n",
      "Epoch 45 Batch 200 Loss 0.0067\n",
      "Epoch 45 Batch 300 Loss 0.0036\n",
      "Epoch 45 Loss 0.0079\n",
      "Time taken for 1 epoch 160.53168034553528 sec\n",
      "\n",
      "Epoch 46 Batch 0 Loss 0.0073\n",
      "Epoch 46 Batch 100 Loss 0.0023\n",
      "Epoch 46 Batch 200 Loss 0.0020\n",
      "Epoch 46 Batch 300 Loss 0.0082\n",
      "Epoch 46 Loss 0.0088\n",
      "Time taken for 1 epoch 161.08413529396057 sec\n",
      "\n",
      "Epoch 47 Batch 0 Loss 0.0065\n",
      "Epoch 47 Batch 100 Loss 0.0094\n",
      "Epoch 47 Batch 200 Loss 0.0111\n",
      "Epoch 47 Batch 300 Loss 0.0229\n",
      "Epoch 47 Loss 0.0152\n",
      "Time taken for 1 epoch 161.01456212997437 sec\n",
      "\n",
      "Epoch 48 Batch 0 Loss 0.0253\n",
      "Epoch 48 Batch 100 Loss 0.0312\n",
      "Epoch 48 Batch 200 Loss 0.0230\n",
      "Epoch 48 Batch 300 Loss 0.0132\n",
      "Epoch 48 Loss 0.0275\n",
      "Time taken for 1 epoch 156.79422855377197 sec\n",
      "\n",
      "Epoch 49 Batch 0 Loss 0.0198\n",
      "Epoch 49 Batch 100 Loss 0.0221\n",
      "Epoch 49 Batch 200 Loss 0.0165\n",
      "Epoch 49 Batch 300 Loss 0.0264\n",
      "Epoch 49 Loss 0.0188\n",
      "Time taken for 1 epoch 151.68398880958557 sec\n",
      "\n",
      "Epoch 50 Batch 0 Loss 0.0137\n",
      "Epoch 50 Batch 100 Loss 0.0112\n",
      "Epoch 50 Batch 200 Loss 0.0102\n",
      "Epoch 50 Batch 300 Loss 0.0155\n",
      "Epoch 50 Loss 0.0124\n",
      "Time taken for 1 epoch 155.34948325157166 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50 # 50 测试需要，设置训练轮数为 2， 实际为保证效果，建议设置为 50\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    # 获取 gru 的初始状态\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,batch,batch_loss.numpy()))\n",
    "    if (epoch + 1) % 2 == 0: \n",
    "        checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "372b6dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    \"\"\"Translate a sentence\n",
    "    Args:\n",
    "    sentence: the test sentence \n",
    "    \"\"\"\n",
    "    # max_length_targ 38, max_length_inp 64\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    sentence = preprocess_chinese(sentence)\n",
    "    # convert each word to the index in the test sentence\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],maxlen=max_length_inp,padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = ''\n",
    "    # hidden shape == (1, 1024)\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    # enc out shape == (1, max_length_inp, 1024) -> (1, 46, 1024)\n",
    "    # enc hidden shape == (1, 1024)\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,dec_hidden,enc_out)\n",
    "        # storing the attention weigths to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "        # print(attention_weights)\n",
    "        # get the index which has the highest probability\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        # convert the index to the word\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "        # when the decoder predicts the end, stop prediction\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "        # the predicted id is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    return result, sentence, attention_plot\n",
    "\n",
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    # maybe you need to change the fname based on your system, so that the Chinese can be displayed in the plot\n",
    "    #设置字体为楷体\n",
    "    #matplotlib.rcParams['font.sans-serif'] = ['KaiTi']\n",
    "    font = FontProperties(fname=\"/usr/share/fonts/truetype/droid/DroidSansFallbackFull.ttf\", size=14)\n",
    "    # set the size of the plot\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    # cmap means color map, viridis means blue-green-yellow\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    fontdict = {'fontsize': 14}\n",
    "    # set the x-tick/y-tick labels with list of string labels\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, fontproperties=font)\n",
    "    #ax.set_xticklabels([''] + sentence, fontdict=fontdict)\n",
    "    #ax.set_yticklabels([''] + predicted_sentence, fontproperties=font, fontdict=fontdict)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "    # set tick locators\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    plt.show()\n",
    "\n",
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2669358f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/chinese-eng/ckpt-25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd961b96d30>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir = 'checkpoints/chinese-eng'\n",
    "print(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4abfb022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> 这是 一只 猫 <end>\n",
      "Predicted translation: this is a cat . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate('这是一只猫')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afda1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2.1",
   "language": "python",
   "name": "tf2.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
